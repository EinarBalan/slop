{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35b69a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU openai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "776013d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    \"google/gemma-3-4b-it\",\n",
    "    \"google/gemma-3-27b-it\",\n",
    "    \"gpt-5\"\n",
    "]\n",
    "\n",
    "\n",
    "# Load dataset categories from JSON file\n",
    "DATASET1_NAMES = [\n",
    "    \"minecraft\",\n",
    "    \"ucla\",\n",
    "    \"nostupidquestions\",\n",
    "    \"copypasta\",\n",
    "    \"varietypack\",\n",
    "]\n",
    "DATASETS1 = [\n",
    "    {\n",
    "        \"minecraft\": 1,  \n",
    "    },\n",
    "    {\n",
    "        \"ucla\": 1,  \n",
    "    },\n",
    "    {\n",
    "        \"nostupidquestions\": 1,  \n",
    "    },\n",
    "    {\n",
    "        \"copypasta\": 1,  \n",
    "    },\n",
    "    {\n",
    "        \"nerdy\": 1,  \n",
    "        \"personal\": 1,\n",
    "        \"amitheasshole\": 1,\n",
    "        \"tech\": 1,\n",
    "        \"pop\": 1,\n",
    "        \"animals\": 1, \n",
    "        \"boomerhumor\": 1,\n",
    "        \"copypasta\": 1,\n",
    "        \"creative\": 1,\n",
    "        \"food\": 1,\n",
    "        \"nba\": 1,\n",
    "        \"religion\": 1,\n",
    "        \"school\": 1,\n",
    "        \"ucla\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "DATASET2_NAMES = [\n",
    "    \"nerdy\",\n",
    "    \"personal\",\n",
    "    \"unalike\",\n",
    "    \"alike\",\n",
    "    \"formatspecific\",\n",
    "    \"college\",\n",
    "    \"newmother\",\n",
    "]\n",
    "DATASETS2 = [\n",
    "    {\n",
    "        \"nerdy\": 1,  \n",
    "    },\n",
    "    {\n",
    "        \"personal\": 1,  \n",
    "    },\n",
    "    { # unalike\n",
    "        \"pop\": 1,  \n",
    "        \"religion\": 1,\n",
    "        \"tech\": 1\n",
    "    },\n",
    "    { # alike\n",
    "        \"tech\": 1,\n",
    "        \"nerdy\": 1,\n",
    "        \"finance\": 1,\n",
    "    },\n",
    "    { # format specific\n",
    "        \"copypasta\": 1,\n",
    "        \"nostupidquestions\": 1,\n",
    "        \"amitheasshole\": 1,\n",
    "    },\n",
    "    { # college student\n",
    "        \"ucla\": 1,\n",
    "        \"nerdy\": 1,\n",
    "        \"okbuddy\": 1,\n",
    "        # \"copypasta\": 1,\n",
    "        \"pop\": 1,\n",
    "        \"food\": 1,\n",
    "        \"animals\": 1,\n",
    "    },\n",
    "    { # new mother\n",
    "        \"pregnancy\": 1,\n",
    "        \"parenting\": 1,\n",
    "        \"baby\": 1,\n",
    "        \"food\": 1,\n",
    "        \"amitheasshole\": 1,\n",
    "        \"pop\": 1,\n",
    "        \"boomerhumor\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "TRAIN_SIZES = [\n",
    "    10, 20, 50, 100, 250, 500, 1000,2000\n",
    "]\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    \"self defined\",\n",
    "    \"summary\",\n",
    "    \"like history\",\n",
    "    # \"fine tune\",\n",
    "    \"soft prompt\",\n",
    "]\n",
    "\n",
    "PROMPT_TOKENS = 64\n",
    "MICRO_BATCH_SIZE = 1\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "LEARNING_RATE = 0.2\n",
    "NUM_TRAIN_STEPS = 1000  \n",
    "MAX_SEQ_LEN = 2048\n",
    "\n",
    "MODEL_OUTPUT_DIR = \"models\"\n",
    "GENERATED_OUTPUT_DIR = \"generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a039cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import json\n",
    "import re\n",
    "import random, math\n",
    "\n",
    "def load_datasets_proportional_objects(datasets_dict: Dict[str, float], total_posts: int) -> List[dict]:\n",
    "    examples: List[dict] = []\n",
    "    \n",
    "    # Get total of all values in datasets_dict\n",
    "    total_proportion = sum(datasets_dict.values())\n",
    "    for dataset_name, proportion in datasets_dict.items():\n",
    "        # Calculate number of posts for this dataset\n",
    "        factor = proportion / total_proportion\n",
    "        target_count = math.ceil(total_posts * factor)\n",
    "        # print(f\"Loading {target_count} posts from {dataset_name} dataset ({factor*100:.1f}%)\")\n",
    "        \n",
    "        # Load sampled Reddit posts from JSON created by sample-posts.py\n",
    "        # Each item is a dict with keys: title, subreddit, self_text\n",
    "        try:\n",
    "            with open(f\"../../../datasets/{dataset_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                reddit_posts: List[dict] = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Could not find dataset file for {dataset_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Filter valid posts (must have self_text and no image_url)\n",
    "        valid_posts = []\n",
    "        for p in reddit_posts:\n",
    "            title = p.get(\"title\", \"\")\n",
    "            self_text = p.get(\"self_text\", \"\")\n",
    "            subreddit = p.get(\"subreddit\", \"\")\n",
    "            image_url = p.get(\"image_url\", \"\")\n",
    "            \n",
    "            if self_text and not image_url:\n",
    "                valid_posts.append({\n",
    "                    \"title\": title,\n",
    "                    \"self_text\": self_text,\n",
    "                    \"subreddit\": subreddit,\n",
    "                })\n",
    "        \n",
    "        # print(f\"Found {len(valid_posts)} valid posts in {dataset_name}\")\n",
    "        \n",
    "        # Sample the target number of posts\n",
    "        if len(valid_posts) >= target_count:\n",
    "            # Randomly sample target_count posts\n",
    "            sampled_posts = random.sample(valid_posts, target_count)\n",
    "        else:\n",
    "            # Use all available posts if we don't have enough\n",
    "            print(f\"Warning: Only {len(valid_posts)} posts available, using all\")\n",
    "            sampled_posts = valid_posts\n",
    "        \n",
    "        examples.extend(sampled_posts)\n",
    "    \n",
    "    # Shuffle the final dataset to mix posts from different datasets\n",
    "    random.shuffle(examples)\n",
    "    \n",
    "    # print(f\"Loaded dataset {datasets_dict} with {total_posts} posts\")\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c52c11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title: lag issue\\n self_text: Anyone else have this issue with bedrock where while you are holding the map on your offhand the game lags\\n subreddit: Minecraft\\n\\ntitle: Can my brother with a Mac no longer play Minecraft with us?\\n self_text: Itâ€™s saying only pc is this really true?\\n subreddit: Minecraft\\n\\ntitle: How do i get rid of pillager raid symbol.\\n self_text: I killed some pillagers now the raid wont stop and they wont stop sounding the horn what do i do to make it stop.\\n subreddit: Minecraft\\n\\ntitle: Ray tracing for console\\n self_text: Is there any new information for Ray tracing coming to next gen consoles\\n subreddit: Minecraft\\n\\ntitle: Looking for a texture pack\\n self_text: Anyone know any good texture packs that make the trees appear as cherry blossoms. Or just any aesthetic texture packs that prioritise the colours pink/purple?\\n subreddit: Minecraft\\n\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_data = load_datasets_proportional_objects({ \"minecraft\": 1 }, 5)\n",
    "\n",
    "prompt_data_str = \"\".join(\n",
    "    f\"title: {p['title']}\\n self_text: {p['self_text']}\\n subreddit: {p['subreddit']}\\n\\n\"\n",
    "    for p in prompt_data\n",
    ")\n",
    "prompt_data_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84b243df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# judge whether each generated post adheres to dataset category, heuristic based on word content and llm judge\n",
    "\n",
    "from openai import OpenAI\n",
    "import os, dotenv\n",
    "from functools import reduce\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def judge_post(post, dataset):\n",
    "    posts = load_datasets_proportional_objects(dataset, 100)\n",
    "    posts_str = \"\".join(\n",
    "        f\"title: {p['title']}\\n self_text: {p['self_text']}\\n subreddit: {p['subreddit']}\\n\\n\"\n",
    "        for p in posts\n",
    "    )\n",
    "    \n",
    "    SYS_PROMPT = \"\"\"\\\n",
    "# Role and Objective\n",
    "- Act as a judge to evaluate Reddit posts for similarity and appropriateness relative to a given dataset.\n",
    "\n",
    "# Checklist\n",
    "Begin with a concise checklist (3-7 bullets) of what you will do; keep items conceptual, not implementation-level.\n",
    "\n",
    "# Instructions\n",
    "- Receive a single Reddit post and a dataset of posts as context.\n",
    "- Assess if the post's style, content, and coherence align with the patterns in the dataset, paying special attention to common subreddit formats and conventions.\n",
    "- ignore any tokens such as <eos>\n",
    "\n",
    "## Sub-categories\n",
    "- **style_adherence**: Rate as 1 if the writing style matches the dataset (including format conventions typical for specific subreddits, e.g., AITA, NoStupidQuestions); otherwise 0.\n",
    "- **content_adherence**: Rate as 1 if the content aligns with the dataset and the post's subreddit; otherwise 0. If the subreddit is right but the main content is not, set to 0.\n",
    "- **coherence**: Rate as 1 if the post is as coherent as typical posts in the dataset; otherwise 0.\n",
    "\n",
    "# Context\n",
    "- Example dataset and posts provided for reference.\n",
    "- Enforce strict field presence: each post must have a valid title, self_text, and subreddit.\n",
    "- If any required fields are missing or malformed, output all values as 0.\n",
    "\n",
    "# Reasoning Steps\n",
    "- Review all fields for presence and valid form.\n",
    "- Compare post with dataset patterns in style, content, and logical coherence.\n",
    "\n",
    "# Planning and Verification\n",
    "- Require: title, self_text, and subreddit fields.\n",
    "- Validate the JSON object fields and assess individual criteria stepwise.\n",
    "- After making your assessment, validate that the output matches the specification and self-correct if necessary.\n",
    "\n",
    "# Output Format\n",
    "Respond only with a JSON object in this structure (no other text):\n",
    "```json\n",
    "{\n",
    "  \"style_adherence\": 0 or 1,\n",
    "  \"content_adherence\": 0 or 1,\n",
    "  \"coherence\": 0 or 1\n",
    "}\n",
    "```\n",
    "# Output Format (Specification)\n",
    "Include exactly the following fields as integer 0 or 1 values (except the explanation which can be a string):\n",
    "- style_adherence\n",
    "- content_adherence\n",
    "- coherence\n",
    "- explanation\n",
    "\n",
    "# Verbosity\n",
    "- Output must be concise: strictly a single JSON object.\n",
    "\n",
    "# Stop Conditions\n",
    "- Do not output any text outside the JSON object.\n",
    "- If any post field is missing or malformed, return all-zeroes JSON.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    USER_PROMPT = f\"\"\"\n",
    "Here's the dataset:\n",
    "\n",
    "{posts_str}\n",
    "\n",
    "Here's the post you need to judge:\n",
    "\n",
    "{post}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        instructions=SYS_PROMPT,\n",
    "        input=USER_PROMPT,\n",
    "    )\n",
    "    \n",
    "    # print(\"Judged post for dataset: \", dataset)\n",
    "    \n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "    \n",
    "# load in 100 posts from dataset and judge whether the generated post adheres to the style and content of the dataset as well as the overall coherence of the generated post relative to the dataset\n",
    "\n",
    "# load a handful of psots from each generated file and see how often i agree with the llm judgement (obviously I need to judge before the llm judgement is shown)\n",
    "\n",
    "# three judgements:\n",
    "# 1. does the post adhere to the style of the dataset?\n",
    "# 2. does the post adhere to the content of the dataset?\n",
    "# 3. is the post coherent?\n",
    "\n",
    "# in prompt show example dataset and generated posts as well as my judgements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8790cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'style_adherence': 0,\n",
       " 'content_adherence': 0,\n",
       " 'coherence': 0,\n",
       " 'explanation': 'Missing or empty subreddit field; required fields not properly provided.'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "post = \"\"\"title: I need a name for my son,\n",
    "    self_text: My wife and I are having a baby, and we're trying to decide on a name for our boy. We want something that is strong and traditional but also unique and modern. We have been going back and forth with names like Henry, George, William, James, Jack, Charlie, Finn, Owen, Leo, Caleb, Noah, Jude, Jasper, Silas, Luke, Ethan, Benjamin, Samuel, David, Alexander, Daniel, Arthur, Charles, Oliver, Theodore, Edward, Michael, Joseph, Isaac, John, Peter, Matthew, Thomas, Robert, Paul, Richard, Justin, Ryan, Jason, Brian, Christopher, Nicholas, Jacob, Logan, Aiden, Connor, Jackson, Wyatt, Julian, Tyler, Dalton, Grayson, Lincoln, Winston, Milo, Levi, Silas, Asher, Ezra, Zion, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude, Jude\n",
    "    subreddit: \"\"\"\n",
    "dataset = DATASETS1[3]\n",
    "judgement = json.loads(judge_post(post, dataset))\n",
    "\n",
    "judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54f2e9",
   "metadata": {},
   "source": [
    "## Judgement Sample for Agreement Rate (100 posts across each all the files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e525d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated posts\n",
    "def load_generated_posts(ablation, model, dataset_name, train_size):\n",
    "    with open(f\"../generated/{ablation}/{model}/{dataset_name}/{train_size}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "281a4433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Can anyone else have trouble with my Xbox?\n",
      " self_text: It keeps saying that it cant connect to the server I'm on. I made sure everything was working, but now I just get a message saying that it cant connect to the server. My friends are able to connect fine so I'm wondering if its something specific to me.\n",
      " subreddit: Minecraft<eos>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'style_adherence': 1,\n",
       " 'content_adherence': 1,\n",
       " 'coherence': 1,\n",
       " 'explanation': '- Checklist:\\n  - Verify required fields are present and valid (title, self_text, subreddit), handling the <eos> token if present.\\n  - Compare post style to dataset conventions (reddit/minecraft Q&A format).\\n  - Compare content to dataset topics (Minecraft crossplay/connectivity issues).\\n  - Assess coherence and readability vs. dataset norm.\\n- Assessment: style_adherence=1, content_adherence=1, coherence=1. The post is a clear Minecraft connectivity question typical of the dataset.'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "post = load_generated_posts(\"train_size_ablation\", MODELS[0], \"minecraft\", 100)[2]\n",
    "post = f\"title: {post['title']}\\n self_text: {post['self_text']}\\n subreddit: {post['subreddit']}\\n\\n\"\n",
    "print(post)\n",
    "dataset = DATASETS1[0]\n",
    "judgement = json.loads(judge_post(post, dataset))\n",
    "\n",
    "judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11169a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "judgements = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "for model in tqdm(MODELS, desc=\"Models\"): # cost: about $5 for 120 judgements\n",
    "    if model == \"gpt-5\": continue # skip gpt-5\n",
    "    for dataset in tqdm([{\"minecraft\": 1}, {\"copypasta\": 1}, {\"ucla\": 1}], desc=\"Datasets\"):\n",
    "        dataset_name = list(dataset.keys())[0]\n",
    "        for train_size in tqdm([10, 100], desc=\"Train Sizes\"):\n",
    "            generated_posts = load_generated_posts(\"train_size_ablation\", model, dataset_name, train_size)[:10]\n",
    "            \n",
    "            for post in tqdm(generated_posts, desc=\"Posts\"):\n",
    "                post = f\"title: {post['title']}\\n self_text: {post['self_text']}\\n subreddit: {post['subreddit']}\\n\\n\"\n",
    "                judgement = json.loads(judge_post(post, dataset))\n",
    "                print(post)\n",
    "                print(judgement)\n",
    "                judgements.append(judgement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8497321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "for model in MODELS:\n",
    "    if model == \"gpt-5\": continue # skip gpt-5\n",
    "    for dataset in [{\"minecraft\": 1}, {\"copypasta\": 1}, {\"ucla\": 1}]:\n",
    "        dataset_name = list(dataset.keys())[0]\n",
    "        for train_size in [10, 100]:\n",
    "            generated_posts = load_generated_posts(\"train_size_ablation\", model, dataset_name, train_size)[:10]\n",
    "            posts.extend(generated_posts)\n",
    "\n",
    "# write judgments to file\n",
    "with open(\"judgements.json\", \"w\") as f:\n",
    "    # combine posts and judgements\n",
    "    for post, judgement in zip(posts, judgements):\n",
    "        post[\"judgement\"] = judgement\n",
    "    json.dump(posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ed1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "style_adherence_acc = 0\n",
    "content_adherence_acc = 0\n",
    "coherence_acc = 0\n",
    "\n",
    "total_posts = len(posts)\n",
    "with open(\"judgements-gpt5.json\", \"r\") as f:\n",
    "    judgements = json.load(f)\n",
    "\n",
    "for post in judgements:\n",
    "    print(\"title: \", post[\"title\"])\n",
    "    print(\"self_text: \", post[\"self_text\"])\n",
    "    print(\"subreddit: \", post[\"subreddit\"])\n",
    "    \n",
    "    judgement = post[\"judgement\"]\n",
    "    style_adherence = input(\"style_adherence: \")\n",
    "    content_adherence = input(\"content_adherence: \")\n",
    "    coherence = input(\"coherence: \")\n",
    "    \n",
    "    style_adherence_acc += 1 if style_adherence == judgement[\"style_adherence\"] else 0\n",
    "    content_adherence_acc += 1 if content_adherence == judgement[\"content_adherence\"] else 0\n",
    "    coherence_acc += 1 if coherence == judgement[\"coherence\"] else 0\n",
    "    \n",
    "    print(judgement, \"\\n\\n\")\n",
    "    \n",
    "\n",
    "style_adherence_acc /= total_posts\n",
    "content_adherence_acc /= total_posts\n",
    "coherence_acc /= total_posts\n",
    "\n",
    "print(f\"Style adherence accuracy: {style_adherence_acc}\")\n",
    "print(f\"Content adherence accuracy: {content_adherence_acc}\")\n",
    "print(f\"Coherence accuracy: {coherence_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb47ed",
   "metadata": {},
   "source": [
    "## Judge all posts\n",
    "\n",
    "I've decided not to use llm judge bc the reliability is too low. i have fully committed to doing nothing except read slop reddit posts and judge them for the next few days. yeehaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train size ablation\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "judgments = []\n",
    "for model in tqdm(MODELS, desc=\"Models\"): # cost: about $5 for 120 judgements\n",
    "    if model == \"gpt-5\": continue # skip gpt-5\n",
    "    for dataset_name, dataset in tqdm(zip(DATASET1_NAMES, DATASETS1), desc=\"Datasets\"):\n",
    "        for train_size in tqdm(TRAIN_SIZES[:6], desc=\"Train Sizes\"): # 10, 20, 50, 100, 250, 500\n",
    "            style_adherence_count = 0\n",
    "            content_adherence_count = 0\n",
    "            coherence_count = 0\n",
    "            \n",
    "            generated_posts = load_generated_posts(\"train_size_ablation\", model, dataset_name, train_size)[:50] # only judge half of the posts bc i am short on time and money\n",
    "            \n",
    "            for post in tqdm(generated_posts, desc=\"Posts\"):\n",
    "                post = f\"title: {post['title']}\\n self_text: {post['self_text']}\\n subreddit: {post['subreddit']}\\n\\n\"\n",
    "                judgement = json.loads(judge_post(post, dataset))\n",
    "\n",
    "                style_adherence_count += judgement[\"style_adherence\"]\n",
    "                content_adherence_count += judgement[\"content_adherence\"]\n",
    "                coherence_count += judgement[\"coherence\"]\n",
    "                \n",
    "            style_adherence = style_adherence_count / len(generated_posts)\n",
    "            content_adherence = content_adherence_count / len(generated_posts)\n",
    "            coherence = coherence_count / len(generated_posts)\n",
    "            \n",
    "            judgments.append({\n",
    "                \"model\": model,\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"train_size\": train_size,\n",
    "                \"style_adherence\": style_adherence,\n",
    "                \"content_adherence\": content_adherence,\n",
    "                \"coherence\": coherence\n",
    "            })\n",
    "# write to json\n",
    "with open(\"judgements-train-size-ablation.json\", \"w\") as f:\n",
    "    json.dump(judgments, f)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cc12e",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224621a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding cos similarity between posts in the generated dataset to see how varied the generated posts are\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
