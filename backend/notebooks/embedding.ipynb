{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef58e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary path: /Users/einar/Developer/Projects/Web/slop/backend/data/generated/experiment_ablation/google/gemma-3-27b-it/personal/summary.json\n",
      "Soft prompt path: /Users/einar/Developer/Projects/Web/slop/backend/data/generated/experiment_ablation/google/gemma-3-27b-it/personal/soft prompt.json\n",
      "Summary posts used: 50\n",
      "Soft prompt posts used: 50\n",
      "{'summary': {'R': 0.778335, 'angular_variance_resultant': 0.221665}, 'soft_prompt': {'R': 0.434592, 'angular_variance_resultant': 0.565408}, 'combined': {'R': 0.527274, 'angular_variance_resultant': 0.472726}}\n"
     ]
    }
   ],
   "source": [
    "# Angular variance resultant for generated posts\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List\n",
    "import math\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Resolve paths relative to this notebook's directory\n",
    "notebooks_dir = Path.cwd()\n",
    "backend_dir = notebooks_dir.parent\n",
    "base = backend_dir / 'data' / 'generated' / 'experiment_ablation' / 'google' / 'gemma-3-27b-it' / 'personal'\n",
    "\n",
    "summary_path = base / 'summary.json'\n",
    "soft_candidates = ['soft prompt.json', 'softprompt.json', 'soft_prompt.json']\n",
    "soft_path = None\n",
    "for name in soft_candidates:\n",
    "    candidate = base / name\n",
    "    if candidate.exists():\n",
    "        soft_path = candidate\n",
    "        break\n",
    "\n",
    "print('Summary path:', summary_path)\n",
    "print('Soft prompt path:', soft_path)\n",
    "\n",
    "assert summary_path.exists(), f\"Missing file: {summary_path}\"\n",
    "assert soft_path and soft_path.exists(), \"Missing soft prompt file (tried: 'soft prompt.json', 'softprompt.json', 'soft_prompt.json')\"\n",
    "\n",
    "\n",
    "def load_posts(path: Path) -> List[dict]:\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        return []\n",
    "    return [p for p in data if isinstance(p, dict)]\n",
    "\n",
    "\n",
    "def extract_texts(posts: List[dict]) -> List[str]:\n",
    "    texts: List[str] = []\n",
    "    for p in posts:  # align with UI cap\n",
    "        title = (p.get('title') or '').strip()\n",
    "        body = (p.get('self_text') or '').strip()\n",
    "        if title and body:\n",
    "            texts.append(f\"{title}\\n\\n{body}\")\n",
    "        else:\n",
    "            texts.append(title or body)\n",
    "    return [t for t in texts if t]\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def embed_texts(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', batch_size: int = 32) -> torch.Tensor:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "        summed = torch.sum(last_hidden_state * mask, dim=1)\n",
    "        counts = torch.clamp(mask.sum(dim=1), min=1e-6)\n",
    "        return summed / counts\n",
    "\n",
    "    all_embs: List[torch.Tensor] = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        out = model(**enc)\n",
    "        pooled = mean_pool(out.last_hidden_state, enc['attention_mask'])\n",
    "        all_embs.append(pooled.cpu())\n",
    "    embs = torch.cat(all_embs, dim=0)\n",
    "    # L2 normalize (unit vectors)\n",
    "    embs = torch.nn.functional.normalize(embs, p=2, dim=1)\n",
    "    return embs\n",
    "\n",
    "\n",
    "def angular_resultant_and_variance(unit_vectors: torch.Tensor) -> tuple[float, float]:\n",
    "    # unit_vectors: [N, D], L2-normalized rows\n",
    "    mean_vec = unit_vectors.mean(dim=0)\n",
    "    R = float(torch.linalg.vector_norm(mean_vec))  # mean resultant length in [0,1]\n",
    "    V = 1.0 - R  # angular variance resultant\n",
    "    return R, V\n",
    "\n",
    "\n",
    "# Load\n",
    "summary_posts = load_posts(summary_path)\n",
    "soft_posts = load_posts(soft_path)\n",
    "\n",
    "summary_texts = extract_texts(summary_posts)\n",
    "soft_texts = extract_texts(soft_posts)\n",
    "\n",
    "print(f\"Summary posts used: {len(summary_texts)}\")\n",
    "print(f\"Soft prompt posts used: {len(soft_texts)}\")\n",
    "\n",
    "# Embed\n",
    "summary_embs = embed_texts(summary_texts)\n",
    "soft_embs = embed_texts(soft_texts)\n",
    "all_embs = torch.cat([summary_embs, soft_embs], dim=0) if len(soft_embs) else summary_embs\n",
    "\n",
    "# Compute metrics\n",
    "R_sum, V_sum = angular_resultant_and_variance(summary_embs)\n",
    "R_soft, V_soft = angular_resultant_and_variance(soft_embs)\n",
    "R_all, V_all = angular_resultant_and_variance(all_embs)\n",
    "\n",
    "print({\n",
    "    'summary': {'R': round(R_sum, 6), 'angular_variance_resultant': round(V_sum, 6)},\n",
    "    'soft_prompt': {'R': round(R_soft, 6), 'angular_variance_resultant': round(V_soft, 6)},\n",
    "    'combined': {'R': round(R_all, 6), 'angular_variance_resultant': round(V_all, 6)},\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd230f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "from openai import OpenAI\n",
    "import os, dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d4899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=\"title: Is there a way/mod that would dissable military clothing ?\\n self_text: I am looking for a way/mod that would dissable military clothing a for rp so it would feel more authentic.\\n subreddit: projectzomboid<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding1 = response.data[0].embedding\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Is anyone else experiencing extreme lag spikes in Warzone? self_text: Ever since the latest patch, I've been getting massive lag spikes every few minutes, even though my ping stays relatively stable. It's making the game nearly unplayable. I've tried restarting my router, verifying game files, and lowering my graphic settings, but nothing seems to fix it. Has anyone else encountered this issue, and if so, have you found a solution?\\n subreddit: Warzone<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding2 = response.data[0].embedding\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"title: Is it normal for my cat to knead my hair?\\n self_text: My cat loves to climb on my lap and knead, which is cute, but lately she’s been kneading *my hair* instead of a blanket or my clothes. It doesn’t hurt, but it’s…weird. Is this a common behavior? Should I discourage it?\\n subreddit: cats<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding3 = response.data[0].embedding\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"title: Dog keeps stealing socks\\n self_text: My golden retriever loves to steal socks, and then hides them all over the house. I’ve tried redirecting with toys, but he’s obsessed with socks. Any advice on how to stop this behavior?\\n subreddit: dogs<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding4 = response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480cfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=\"title: My partner keeps forgetting to reimburse me for shared expenses\\n self_text: Okay, so we’ve been together 2 years and live together. We don’t have joint finances – mostly because we both had messy situations before meeting and are hesitant to fully merge everything. But we *do* split bills pretty evenly. The problem is, I often end up fronting costs for things like groceries, household supplies, or even date nights, with the understanding he’ll Venmo me his half. And…he just doesn't. Not consistently, anyway. He’ll say he “forgot,” or that money is tight (even though he just bought a new video game). I've brought it up multiple times, trying to be calm and rational (\\\"Hey, could you send over $40 for groceries?\\\"), but it always feels like pulling teeth. Last week I covered almost all of our gas for a road trip and still haven’t seen a dime. It’s not huge amounts individually, but it adds up! And honestly, it feels disrespectful, like my time and effort aren't valued. Is it ridiculous to feel this way? Am I supposed to just constantly remind him? I'm starting to resent having to ask at all. AITA for expecting him to follow through when we agree on splitting costs? Any advice on how to handle this without blowing up at him?\\n subreddit: relationships<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding5 = response.data[0].embedding\n",
    "response  = client.embeddings.create(\n",
    "    input=\" title: My (32F) partner (35M) keeps \\\"forgetting\\\" to reimburse me for shared expenses - am I being unreasonable to be frustrated?\\n self_text: Okay, so we’ve been together 3 years, living together for 1.5. We don’t have joint finances – both very independent people which was great at first. But lately, it feels like I’m constantly fronting costs for things *we* both benefit from (groceries, utilities, date nights, even pet supplies). He always says he’ll Venmo me, genuinely apologizes for forgetting, then…doesn’t. Or remembers weeks later after I’ve brought it up again. It’s not huge amounts each time ($20-$50 usually), but it adds up! And honestly, it feels disrespectful now. Like my time & money aren't valued. I’ve tried gently reminding him, then more directly asking, and even suggesting we alternate who pays for what each week. Nothing sticks. AITA for getting increasingly annoyed by this? Is there a way to address this without starting a massive fight? I just want a fair split and some acknowledgement that I’m contributing equally.\\n subreddit: relationships<end_of_turn>\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "embedding6 = response.data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cfa61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295794081681001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate cosine similarity between embedding1 and embedding2\n",
    "# cosine_similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "# print(cosine_similarity)\n",
    "\n",
    "# # calculate cosine similarity between embedding1 and embedding3\n",
    "# cosine_similarity = np.dot(embedding1, embedding3) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding3))\n",
    "# print(cosine_similarity)\n",
    "\n",
    "# # calculate cosine similarity between embedding3 and embedding4\n",
    "# cosine_similarity = np.dot(embedding3, embedding4) / (np.linalg.norm(embedding3) * np.linalg.norm(embedding4))\n",
    "# print(cosine_similarity)\n",
    "\n",
    "# calculate cosine similarity between embedding5 and embedding6\n",
    "cosine_similarity = np.dot(embedding5, embedding6) / (np.linalg.norm(embedding5) * np.linalg.norm(embedding6))\n",
    "print(cosine_similarity)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4ae34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34554694215198034\n"
     ]
    }
   ],
   "source": [
    "# Calculate variance across all embeddings\n",
    "embeddings = [embedding1, embedding2, embedding3, embedding4, embedding5, embedding6]\n",
    "\n",
    "def angular_variance_resultant(X):\n",
    "    \"\"\"\n",
    "    1 - resultant length for L2-normalized embeddings.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    Y = X / np.clip(np.linalg.norm(X, axis=1, keepdims=True), 1e-12, None)\n",
    "    R = np.linalg.norm(Y.mean(axis=0))\n",
    "    return 1.0 - R\n",
    "\n",
    "variance = angular_variance_resultant(embeddings)\n",
    "print(variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e915db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install umap-learn hdbscan matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca8dc6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embeddings(embeddings):        \n",
    "    # X = (n, d) embeddings, already normalized\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    X_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "    # Cluster in high-d space\n",
    "    clusterer = hdbscan.HDBSCAN()\n",
    "    labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1], c=labels, cmap=\"tab20\", s=8)\n",
    "    # plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return number of clusters (excluding noise points labeled as -1)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    return n_clusters\n",
    "    \n",
    "print(plot_embeddings(soft_embs))   \n",
    "print(plot_embeddings(summary_embs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c884b9cb",
   "metadata": {},
   "source": [
    "## Load judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "670b1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_posts(path: Path) -> List[object]:\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        return []\n",
    "    # keep both dict and string items; filter out other types\n",
    "    return [p for p in data if isinstance(p, (dict, str))]\n",
    "\n",
    "\n",
    "def parse_string_post(s: str) -> dict | None:\n",
    "    try:\n",
    "        text = str(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "    title = ''\n",
    "    body_lines: List[str] = []\n",
    "    subreddit = ''\n",
    "    in_body = False\n",
    "    for line in text.splitlines():\n",
    "        t = line.lstrip()\n",
    "        if t.lower().startswith('title:'):\n",
    "            title = t.split(':', 1)[1].strip()\n",
    "            in_body = False\n",
    "            continue\n",
    "        if t.lower().startswith('self_text:') or t.lower().startswith('self text:'):\n",
    "            body_lines.append(t.split(':', 1)[1].lstrip())\n",
    "            in_body = True\n",
    "            continue\n",
    "        if t.lower().startswith('subreddit:'):\n",
    "            subreddit = t.split(':', 1)[1].strip()\n",
    "            in_body = False\n",
    "            continue\n",
    "        if in_body:\n",
    "            body_lines.append(line)\n",
    "    self_text = '\\n'.join(body_lines).strip()\n",
    "    if not (title or self_text):\n",
    "        return None\n",
    "    return {'title': title, 'self_text': self_text, 'subreddit': subreddit}\n",
    "\n",
    "\n",
    "def extract_texts(posts: List[object]) -> List[str]:\n",
    "    texts: List[str] = []\n",
    "    for p in posts:\n",
    "        title = ''\n",
    "        body = ''\n",
    "        subreddit = ''\n",
    "        if isinstance(p, dict):\n",
    "            title = (p.get('title') or '').strip()\n",
    "            body = (p.get('self_text') or '').strip()\n",
    "            subreddit = (p.get('subreddit') or '').strip()\n",
    "        elif isinstance(p, str):\n",
    "            parsed = parse_string_post(p)\n",
    "            if not parsed:\n",
    "                continue\n",
    "            title = parsed['title']\n",
    "            body = parsed['self_text']\n",
    "            subreddit = parsed.get('subreddit') or ''\n",
    "        else:\n",
    "            continue\n",
    "        if title and body:\n",
    "            texts.append(f\"{title}\\n\\n{body}\\n\\n{subreddit}\")\n",
    "        else:\n",
    "            texts.append(title or body)\n",
    "    return [t for t in texts if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d66e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up json to add model, experiment, dataset fields based on file path\n",
    "with open('../data/judgements/experiment_ablation_judgements.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for d in data:\n",
    "        d['model'] = d['file_path'].split('/')[-4] + '/' + d['file_path'].split('/')[-3]\n",
    "        d['dataset'] = d['file_path'].split('/')[-2]\n",
    "        d['experiment'] = d['file_path'].split('/')[-1].split('.')[0]\n",
    "    with open('../data/judgements/experiment_ablation_judgements_clean.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "697da478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>adherence</th>\n",
       "      <th>coherence</th>\n",
       "      <th>shown_count</th>\n",
       "      <th>unique</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generated/experiment_ablation/google/gemma-3-4...</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>alike</td>\n",
       "      <td>soft prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generated/experiment_ablation/google/gemma-3-4...</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>alike</td>\n",
       "      <td>like history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generated/experiment_ablation/google/gemma-3-4...</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>alike</td>\n",
       "      <td>self defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generated/experiment_ablation/google/gemma-3-4...</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>alike</td>\n",
       "      <td>summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generated/experiment_ablation/google/gemma-3-4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>college</td>\n",
       "      <td>summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  adherence  coherence  \\\n",
       "0  generated/experiment_ablation/google/gemma-3-4...         42         39   \n",
       "1  generated/experiment_ablation/google/gemma-3-4...         49         49   \n",
       "2  generated/experiment_ablation/google/gemma-3-4...         40         34   \n",
       "3  generated/experiment_ablation/google/gemma-3-4...         31         24   \n",
       "4  generated/experiment_ablation/google/gemma-3-4...          1          1   \n",
       "\n",
       "   shown_count  unique                 model  dataset    experiment  \n",
       "0           50      22  google/gemma-3-4b-it    alike   soft prompt  \n",
       "1           50       7  google/gemma-3-4b-it    alike  like history  \n",
       "2           50       0  google/gemma-3-4b-it    alike  self defined  \n",
       "3           50       0  google/gemma-3-4b-it    alike       summary  \n",
       "4           50       0  google/gemma-3-4b-it  college       summary  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load into pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_json('../data/judgements/experiment_ablation_judgements_clean.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df97cac",
   "metadata": {},
   "source": [
    "## Calculate variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9c77066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_variance(unit_vectors: torch.Tensor) -> tuple[float, float]:\n",
    "    # unit_vectors: [N, D], L2-normalized rows\n",
    "    mean_vec = unit_vectors.mean(dim=0)\n",
    "    R = float(torch.linalg.vector_norm(mean_vec))  # mean resultant length in [0,1]\n",
    "    V = 1.0 - R  # angular variance resultant\n",
    "    return V\n",
    "\n",
    "@torch.inference_mode()\n",
    "def embed_texts(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', batch_size: int = 32) -> torch.Tensor:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "        summed = torch.sum(last_hidden_state * mask, dim=1)\n",
    "        counts = torch.clamp(mask.sum(dim=1), min=1e-6)\n",
    "        return summed / counts\n",
    "\n",
    "    all_embs: List[torch.Tensor] = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        out = model(**enc)\n",
    "        pooled = mean_pool(out.last_hidden_state, enc['attention_mask'])\n",
    "        all_embs.append(pooled.cpu())\n",
    "    embs = torch.cat(all_embs, dim=0)\n",
    "    # L2 normalize (unit vectors)\n",
    "    embs = torch.nn.functional.normalize(embs, p=2, dim=1)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e9a6660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-3-4b-it alike soft prompt 0.6657687127590179\n",
      "google/gemma-3-4b-it alike like history 0.4634689688682556\n",
      "google/gemma-3-4b-it alike self defined 0.18786484003067017\n",
      "google/gemma-3-4b-it alike summary 0.17541402578353882\n",
      "google/gemma-3-4b-it college summary 0.09758579730987549\n",
      "google/gemma-3-4b-it college soft prompt 0.7001872956752777\n",
      "google/gemma-3-4b-it college like history 0.7034116685390472\n",
      "google/gemma-3-4b-it college self defined 0.3103201389312744\n",
      "google/gemma-3-4b-it formatspecific like history 0.6295323669910431\n",
      "google/gemma-3-4b-it formatspecific self defined 0.2685620188713074\n",
      "google/gemma-3-4b-it formatspecific soft prompt 0.6728358864784241\n",
      "google/gemma-3-4b-it formatspecific summary 0.25034523010253906\n",
      "google/gemma-3-4b-it nerdy summary 0.3771069645881653\n",
      "google/gemma-3-4b-it nerdy soft prompt 0.5809314250946045\n",
      "google/gemma-3-4b-it nerdy self defined 0.1450396180152893\n",
      "google/gemma-3-4b-it nerdy like history 0.37341296672821045\n",
      "google/gemma-3-4b-it newmother like history 0.6317931413650513\n",
      "google/gemma-3-4b-it newmother soft prompt 0.574007660150528\n",
      "google/gemma-3-4b-it newmother summary 0.3062490224838257\n",
      "google/gemma-3-4b-it newmother self defined 0.25526946783065796\n",
      "google/gemma-3-4b-it personal summary 0.39120912551879883\n",
      "google/gemma-3-4b-it personal soft prompt 0.5896351635456085\n",
      "google/gemma-3-4b-it personal like history 0.5376088619232178\n",
      "google/gemma-3-4b-it personal self defined 0.6317825317382812\n",
      "google/gemma-3-4b-it unalike like history 0.6230484247207642\n",
      "google/gemma-3-4b-it unalike soft prompt 0.702101081609726\n",
      "google/gemma-3-4b-it unalike self defined 0.08036667108535767\n",
      "google/gemma-3-4b-it unalike summary 0.10798484086990356\n",
      "google/gemma-3-27b-it alike summary 0.21659809350967407\n",
      "google/gemma-3-27b-it alike like history 0.5874954462051392\n",
      "google/gemma-3-27b-it alike self defined 0.269359290599823\n",
      "google/gemma-3-27b-it alike soft prompt 0.6328907608985901\n",
      "google/gemma-3-27b-it college summary 0.21161556243896484\n",
      "google/gemma-3-27b-it college self defined 0.18544542789459229\n",
      "google/gemma-3-27b-it college like history 0.6568061709403992\n",
      "google/gemma-3-27b-it college soft prompt 0.7205198109149933\n",
      "google/gemma-3-27b-it formatspecific like history 0.35459935665130615\n",
      "google/gemma-3-27b-it formatspecific soft prompt 0.7394275665283203\n",
      "google/gemma-3-27b-it formatspecific summary 0.2293027639389038\n",
      "google/gemma-3-27b-it formatspecific self defined 0.3123311400413513\n",
      "google/gemma-3-27b-it nerdy self defined 0.23350876569747925\n",
      "google/gemma-3-27b-it nerdy like history 0.43169164657592773\n",
      "google/gemma-3-27b-it nerdy summary 0.33731597661972046\n",
      "google/gemma-3-27b-it nerdy soft prompt 0.6330915987491608\n",
      "google/gemma-3-27b-it newmother summary 0.2190990447998047\n",
      "google/gemma-3-27b-it newmother soft prompt 0.5236228108406067\n",
      "google/gemma-3-27b-it newmother self defined 0.14310795068740845\n",
      "google/gemma-3-27b-it newmother like history 0.359724223613739\n",
      "google/gemma-3-27b-it personal like history 0.4011561870574951\n",
      "google/gemma-3-27b-it personal summary 0.2035415768623352\n",
      "google/gemma-3-27b-it personal soft prompt 0.5754389762878418\n",
      "google/gemma-3-27b-it personal self defined 0.2936133146286011\n",
      "google/gemma-3-27b-it unalike self defined 0.324740469455719\n",
      "google/gemma-3-27b-it unalike summary 0.3213951587677002\n",
      "google/gemma-3-27b-it unalike soft prompt 0.7255090177059174\n",
      "google/gemma-3-27b-it unalike like history 0.6578435599803925\n",
      "openai/gpt-5 alike summary 0.09325391054153442\n",
      "openai/gpt-5 alike like history 0.26467931270599365\n",
      "openai/gpt-5 alike self defined 0.15200895071029663\n",
      "openai/gpt-5 college summary 0.27413302659988403\n",
      "openai/gpt-5 college self defined 0.49480485916137695\n",
      "openai/gpt-5 college like history 0.4657794237136841\n",
      "openai/gpt-5 formatspecific like history 0.5041787624359131\n",
      "openai/gpt-5 formatspecific summary 0.44270414113998413\n",
      "openai/gpt-5 formatspecific self defined 0.4055292010307312\n",
      "openai/gpt-5 nerdy self defined 0.29366862773895264\n",
      "openai/gpt-5 nerdy like history 0.2591284513473511\n",
      "openai/gpt-5 nerdy summary 0.2964436411857605\n",
      "openai/gpt-5 newmother summary 0.3325830101966858\n",
      "openai/gpt-5 newmother self defined 0.37551355361938477\n",
      "openai/gpt-5 newmother like history 0.36182641983032227\n",
      "openai/gpt-5 personal like history 0.3683054447174072\n",
      "openai/gpt-5 personal summary 0.34001344442367554\n",
      "openai/gpt-5 personal self defined 0.35768771171569824\n",
      "openai/gpt-5 unalike self defined 0.1566954255104065\n",
      "openai/gpt-5 unalike summary 0.40219706296920776\n",
      "openai/gpt-5 unalike like history 0.2975171208381653\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    model = row['model']\n",
    "    dataset = row['dataset']\n",
    "    experiment = row['experiment']\n",
    "\n",
    "    # load posts\n",
    "    posts_path = f'../data/generated/experiment_ablation/{model}/{dataset}/{experiment}.json'\n",
    "    posts = load_posts(Path(posts_path))\n",
    "    variance = None\n",
    "    try:\n",
    "        texts = extract_texts(posts)\n",
    "        if not texts:\n",
    "            raise ValueError('no_texts')\n",
    "        embs = embed_texts(texts)\n",
    "        variance = angular_variance(embs)\n",
    "        # update original DataFrame\n",
    "        df.loc[idx, 'variance'] = variance\n",
    "    except Exception as e:\n",
    "        print(f'{model} {dataset} {experiment} {e}')\n",
    "\n",
    "    print(f'{model} {dataset} {experiment} {variance}')\n",
    "\n",
    "# persist updated DataFrame\n",
    "\n",
    "df.to_json('../data/judgements/experiment_ablation_judgements_clean.json', orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223415c3",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embeddings(embeddings):        \n",
    "    # X = (n, d) embeddings, already normalized\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    X_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "    # Cluster in high-d space\n",
    "    clusterer = hdbscan.HDBSCAN()\n",
    "    labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1], c=labels, cmap=\"tab20\", s=8)\n",
    "    # plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return number of clusters (excluding noise points labeled as -1)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    return n_clusters\n",
    "    \n",
    "print(plot_embeddings(soft_embs))   \n",
    "print(plot_embeddings(summary_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af245fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch plot embeddings (16 subplots per image) with rows=datasets and cols=experiments; save PNGs\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "\n",
    "# Where to save\n",
    "notebooks_dir = Path.cwd()\n",
    "backend_dir = notebooks_dir.parent\n",
    "out_dir = backend_dir / 'data' / 'judgements'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_embeddings_ax(embeddings, ax):\n",
    "    # embeddings expected L2-normalized (embed_texts returns normalized)\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    X_2d = reducer.fit_transform(embeddings)\n",
    "    clusterer = hdbscan.HDBSCAN()\n",
    "    labels = clusterer.fit_predict(embeddings)\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='tab20', s=8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "def make_title(dataset, experiment, model):\n",
    "    return f\"{dataset} / {experiment}\\n{model}\"\n",
    "\n",
    "\n",
    "# Determine experiment columns (prefer a stable order)\n",
    "preferred_experiments = [\n",
    "    'soft prompt',\n",
    "    'like history',\n",
    "    'self defined',\n",
    "    'summary',\n",
    "]\n",
    "all_experiments = list(df['experiment'].astype(str).unique())\n",
    "# Compose the final 4-column order\n",
    "exp_cols = [e for e in preferred_experiments if e in all_experiments]\n",
    "for e in all_experiments:\n",
    "    if e not in exp_cols:\n",
    "        exp_cols.append(e)\n",
    "exp_cols = exp_cols[:4]\n",
    "\n",
    "# Rows are datasets; batch 4 datasets per page\n",
    "datasets = list(df['dataset'].astype(str).unique())\n",
    "datasets.sort()\n",
    "\n",
    "page = 1\n",
    "for start in range(0, len(datasets), 4):\n",
    "    ds_batch = datasets[start:start+4]\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    axs = axs.reshape(4, 4)\n",
    "\n",
    "    for r_idx, dataset in enumerate(ds_batch):\n",
    "        for c_idx, experiment in enumerate(exp_cols):\n",
    "            ax = axs[r_idx, c_idx]\n",
    "            # Pick a matching row (first match) for this dataset+experiment\n",
    "            match = df[(df['dataset'] == dataset) & (df['experiment'] == experiment)]\n",
    "            if match.empty:\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"{dataset} / {experiment}\\n[missing]\", fontsize=9)\n",
    "                continue\n",
    "            row = match.iloc[0]\n",
    "            model = row['model']\n",
    "            posts_path = backend_dir / 'data' / 'generated' / 'experiment_ablation' / model / dataset / f\"{experiment}.json\"\n",
    "            try:\n",
    "                posts = load_posts(Path(posts_path))\n",
    "                texts = extract_texts(posts)\n",
    "                if not texts:\n",
    "                    raise ValueError('no_texts')\n",
    "                embs = embed_texts(texts)\n",
    "                plot_embeddings_ax(embs, ax)\n",
    "                ax.set_title(make_title(dataset, experiment, model), fontsize=9)\n",
    "            except Exception as e:\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"{make_title(dataset, experiment, model)}\\n[error: {e}]\", fontsize=9)\n",
    "\n",
    "    # Label column headers with experiments\n",
    "    for c_idx, experiment in enumerate(exp_cols):\n",
    "        axs[0, c_idx].set_title(f\"{experiment}\", fontsize=11, pad=20)\n",
    "    # Label row headers (left side) with dataset\n",
    "    for r_idx, dataset in enumerate(ds_batch):\n",
    "        axs[r_idx, 0].set_ylabel(dataset, fontsize=11, labelpad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = out_dir / f\"embeddings_page_{page}.png\"\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    page += 1\n",
    "\n",
    "print(f\"Saved {page - 1} image(s) to {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99f31b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/einar/miniconda3/envs/slop/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-model pages to /Users/einar/Developer/Projects/Web/slop/backend/data/judgements\n"
     ]
    }
   ],
   "source": [
    "# One model per PNG: 4x4 grid (rows=datasets, cols=experiments), no per-plot titles\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "\n",
    "# Output directory\n",
    "notebooks_dir = Path.cwd()\n",
    "backend_dir = notebooks_dir.parent\n",
    "out_dir = backend_dir / 'data' / 'judgements'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "preferred_experiments = [\n",
    "    'soft prompt',\n",
    "    'like history',\n",
    "    'self defined',\n",
    "    'summary',\n",
    "]\n",
    "\n",
    "\n",
    "def plot_embeddings_ax(embeddings, ax):\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    X_2d = reducer.fit_transform(embeddings)\n",
    "    labels = hdbscan.HDBSCAN().fit_predict(embeddings)\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='tab20', s=4)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "models = sorted(df['model'].astype(str).unique())\n",
    "\n",
    "for model in models:\n",
    "    mdf = df[df['model'] == model].copy()\n",
    "    # Determine columns (experiments) present for this model\n",
    "    all_exps = list(mdf['experiment'].astype(str).unique())\n",
    "    exp_cols = [e for e in preferred_experiments if e in all_exps]\n",
    "    for e in all_exps:\n",
    "        if e not in exp_cols:\n",
    "            exp_cols.append(e)\n",
    "    exp_cols = exp_cols[:4]\n",
    "\n",
    "    # Determine datasets for this model\n",
    "    datasets = sorted(mdf['dataset'].astype(str).unique())\n",
    "\n",
    "    page = 1\n",
    "    for start in range(0, len(datasets), 7):\n",
    "        ds_batch = datasets[start:start+7]\n",
    "        # Letter size (11 x 8.5 inches) landscape with room for caption\n",
    "        fig, axs = plt.subplots(7, 4, figsize=(11.0, 8.5))\n",
    "        axs = axs.reshape(7, 4)\n",
    "\n",
    "        for r_idx, dataset in enumerate(ds_batch):\n",
    "            for c_idx, experiment in enumerate(exp_cols):\n",
    "                ax = axs[r_idx, c_idx]\n",
    "                match = mdf[(mdf['dataset'] == dataset) & (mdf['experiment'] == experiment)]\n",
    "                if match.empty:\n",
    "                    ax.axis('off')\n",
    "                    continue\n",
    "                row = match.iloc[0]\n",
    "                posts_path = backend_dir / 'data' / 'generated' / 'experiment_ablation' / model / dataset / f\"{experiment}.json\"\n",
    "                try:\n",
    "                    posts = load_posts(Path(posts_path))\n",
    "                    texts = extract_texts(posts)\n",
    "                    if not texts:\n",
    "                        raise ValueError('no_texts')\n",
    "                    embs = embed_texts(texts)\n",
    "                    plot_embeddings_ax(embs, ax)\n",
    "                except Exception:\n",
    "                    ax.axis('off')\n",
    "\n",
    "        # Column headers (experiments)\n",
    "        for c_idx, experiment in enumerate(exp_cols):\n",
    "            axs[0, c_idx].set_title(f\"{experiment}\", fontsize=8, pad=8)\n",
    "        # Row labels (datasets) on the left\n",
    "        for r_idx, dataset in enumerate(ds_batch):\n",
    "            axs[r_idx, 0].set_ylabel(dataset, fontsize=8, labelpad=8)\n",
    "\n",
    "        # Figure title with model\n",
    "        fig.suptitle(model, fontsize=10, y=0.99)\n",
    "\n",
    "        # Use full page; no reserved bottom margin\n",
    "        plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.97])\n",
    "\n",
    "        safe_model = model.replace('/', '-').replace(' ', '_')\n",
    "        out_path = out_dir / f\"embeddings_{safe_model}_page_{page}.png\"\n",
    "        plt.savefig(out_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        page += 1\n",
    "\n",
    "print(f\"Saved per-model pages to {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e17ebd",
   "metadata": {},
   "source": [
    "## Compare Mean Embedding to Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09ee3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import json\n",
    "import re\n",
    "import random, math\n",
    "\n",
    "def load_datasets_proportional_objects(datasets_dict: Dict[str, float], total_posts: int) -> List[dict]:\n",
    "    examples: List[dict] = []\n",
    "    \n",
    "    # Get total of all values in datasets_dict\n",
    "    total_proportion = sum(datasets_dict.values())\n",
    "    for dataset_name, proportion in datasets_dict.items():\n",
    "        # Calculate number of posts for this dataset\n",
    "        factor = proportion / total_proportion\n",
    "        target_count = math.ceil(total_posts * factor)\n",
    "        print(f\"Loading {target_count} posts from {dataset_name} dataset ({factor*100:.1f}%)\")\n",
    "        \n",
    "        # Load sampled Reddit posts from JSON created by sample-posts.py\n",
    "        # Each item is a dict with keys: title, subreddit, self_text\n",
    "        try:\n",
    "            with open(f\"../../datasets/{dataset_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                reddit_posts: List[dict] = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Could not find dataset file for {dataset_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Filter valid posts (must have self_text and no image_url)\n",
    "        valid_posts = []\n",
    "        for p in reddit_posts:\n",
    "            title = p.get(\"title\", \"\")\n",
    "            self_text = p.get(\"self_text\", \"\")\n",
    "            image_url = p.get(\"image_url\", \"\")\n",
    "            \n",
    "            if self_text and not image_url:\n",
    "                valid_posts.append(p)\n",
    "        \n",
    "        print(f\"Found {len(valid_posts)} valid posts in {dataset_name}\")\n",
    "        \n",
    "        # Sample the target number of posts\n",
    "        if len(valid_posts) >= target_count:\n",
    "            # Randomly sample target_count posts\n",
    "            sampled_posts = random.sample(valid_posts, target_count)\n",
    "        else:\n",
    "            # Use all available posts if we don't have enough\n",
    "            print(f\"Warning: Only {len(valid_posts)} posts available, using all\")\n",
    "            sampled_posts = valid_posts\n",
    "        \n",
    "        examples.extend(sampled_posts)\n",
    "    \n",
    "    # Shuffle the final dataset to mix posts from different datasets\n",
    "    random.shuffle(examples)\n",
    "    \n",
    "    print(f\"Loaded dataset {datasets_dict} with {total_posts} posts\")\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0821bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS2 = [\n",
    "    {\n",
    "    \"nerdy\": 1,  \n",
    "    },\n",
    "    {\n",
    "    \"personal\": 1,  \n",
    "    },\n",
    "    { # unalike\n",
    "    \"pop\": 1,  \n",
    "    \"religion\": 1,\n",
    "    \"tech\": 1\n",
    "    },\n",
    "    { # alike\n",
    "        \"tech\": 1,\n",
    "        \"nerdy\": 1,\n",
    "        \"finance\": 1,\n",
    "    },\n",
    "    { # format specific\n",
    "        \"copypasta\": 1,\n",
    "        \"nostupidquestions\": 1,\n",
    "        \"amitheasshole\": 1,\n",
    "    },\n",
    "    { # college student\n",
    "        \"ucla\": 1,\n",
    "        \"nerdy\": 1,\n",
    "        \"okbuddy\": 1,\n",
    "        \"copypasta\": 1,\n",
    "        \"pop\": 1,\n",
    "        \"food\": 1,\n",
    "        \"animals\": 1,\n",
    "    },\n",
    "    { # new mother\n",
    "        \"pregnancy\": 1,\n",
    "        \"parenting\": 1,\n",
    "        \"baby\": 1,\n",
    "        \"food\": 1,\n",
    "        \"amitheasshole\": 1,\n",
    "        \"pop\": 1,\n",
    "        \"boomerhumor\": 1,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd113461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 posts from nerdy dataset (100.0%)\n",
      "Found 271 valid posts in nerdy\n",
      "Loaded dataset {'nerdy': 1} with 100 posts\n",
      "tensor(0.5893)\n",
      "tensor(0.8109)\n"
     ]
    }
   ],
   "source": [
    "original_posts = load_datasets_proportional_objects(DATASETS2[0], 100)\n",
    "posts = load_posts(Path('../data/generated/experiment_ablation/google/gemma-3-27b-it/nerdy/summary.json'))\n",
    "soft_posts = load_posts(Path('../data/generated/experiment_ablation/google/gemma-3-27b-it/nerdy/soft prompt.json'))\n",
    "original_embs = embed_texts(extract_texts(original_posts))\n",
    "summary_embs = embed_texts(extract_texts(posts))\n",
    "soft_embs = embed_texts(extract_texts(soft_posts))\n",
    "\n",
    "# take mean of original_embs\n",
    "original_mean = original_embs.mean(dim=0)\n",
    "\n",
    "# take mean of summary_embs\n",
    "summary_mean = summary_embs.mean(dim=0)\n",
    "\n",
    "# take mean of soft_embs\n",
    "soft_mean = soft_embs.mean(dim=0)\n",
    "\n",
    "# cos similarity between original_mean and summary_mean\n",
    "print(torch.nn.functional.cosine_similarity(original_mean, summary_mean, dim=0))\n",
    "\n",
    "# cos similarity between original_mean and soft_mean\n",
    "print(torch.nn.functional.cosine_similarity(original_mean, soft_mean, dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38fc7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 67 posts from tech dataset (33.3%)\n",
      "Found 150 valid posts in tech\n",
      "Loading 67 posts from nerdy dataset (33.3%)\n",
      "Found 271 valid posts in nerdy\n",
      "Loading 67 posts from finance dataset (33.3%)\n",
      "Found 76 valid posts in finance\n",
      "Loaded dataset {'tech': 1, 'nerdy': 1, 'finance': 1} with 200 posts\n",
      "google/gemma-3-4b-it alike soft prompt cosine_to_original_mean: 0.5942312479019165\n",
      "google/gemma-3-4b-it alike like history cosine_to_original_mean: 0.5810608267784119\n",
      "google/gemma-3-4b-it alike self defined cosine_to_original_mean: 0.6665176749229431\n",
      "google/gemma-3-4b-it alike summary cosine_to_original_mean: 0.5263304710388184\n",
      "Loading 29 posts from ucla dataset (14.3%)\n",
      "Found 1516 valid posts in ucla\n",
      "Loading 29 posts from nerdy dataset (14.3%)\n",
      "Found 271 valid posts in nerdy\n",
      "Loading 29 posts from okbuddy dataset (14.3%)\n",
      "Found 14 valid posts in okbuddy\n",
      "Warning: Only 14 posts available, using all\n",
      "Loading 29 posts from copypasta dataset (14.3%)\n",
      "Found 2000 valid posts in copypasta\n",
      "Loading 29 posts from pop dataset (14.3%)\n",
      "Found 47 valid posts in pop\n",
      "Loading 29 posts from food dataset (14.3%)\n",
      "Found 10 valid posts in food\n",
      "Warning: Only 10 posts available, using all\n",
      "Loading 29 posts from animals dataset (14.3%)\n",
      "Found 43 valid posts in animals\n",
      "Loaded dataset {'ucla': 1, 'nerdy': 1, 'okbuddy': 1, 'copypasta': 1, 'pop': 1, 'food': 1, 'animals': 1} with 200 posts\n",
      "google/gemma-3-4b-it college summary cosine_to_original_mean: 0.3610000014305115\n",
      "google/gemma-3-4b-it college soft prompt cosine_to_original_mean: 0.5732287168502808\n",
      "google/gemma-3-4b-it college like history cosine_to_original_mean: 0.6999966502189636\n",
      "google/gemma-3-4b-it college self defined cosine_to_original_mean: 0.5653713345527649\n",
      "Loading 67 posts from copypasta dataset (33.3%)\n",
      "Found 2000 valid posts in copypasta\n",
      "Loading 67 posts from nostupidquestions dataset (33.3%)\n",
      "Found 2000 valid posts in nostupidquestions\n",
      "Loading 67 posts from amitheasshole dataset (33.3%)\n",
      "Found 2000 valid posts in amitheasshole\n",
      "Loaded dataset {'copypasta': 1, 'nostupidquestions': 1, 'amitheasshole': 1} with 200 posts\n",
      "google/gemma-3-4b-it formatspecific like history cosine_to_original_mean: 0.6712458729743958\n",
      "google/gemma-3-4b-it formatspecific self defined cosine_to_original_mean: 0.5379734039306641\n",
      "google/gemma-3-4b-it formatspecific soft prompt cosine_to_original_mean: 0.7363053560256958\n",
      "google/gemma-3-4b-it formatspecific summary cosine_to_original_mean: 0.6575756669044495\n",
      "Loading 200 posts from nerdy dataset (100.0%)\n",
      "Found 271 valid posts in nerdy\n",
      "Loaded dataset {'nerdy': 1} with 200 posts\n",
      "google/gemma-3-4b-it nerdy summary cosine_to_original_mean: 0.6229721307754517\n",
      "google/gemma-3-4b-it nerdy soft prompt cosine_to_original_mean: 0.769952654838562\n",
      "google/gemma-3-4b-it nerdy self defined cosine_to_original_mean: 0.6176934242248535\n",
      "google/gemma-3-4b-it nerdy like history cosine_to_original_mean: 0.2957664132118225\n",
      "Loading 34 posts from pregnant dataset (16.7%)\n",
      "Found 2000 valid posts in pregnant\n",
      "Loading 34 posts from parenting dataset (16.7%)\n",
      "Found 2000 valid posts in parenting\n",
      "Loading 34 posts from food dataset (16.7%)\n",
      "Found 10 valid posts in food\n",
      "Warning: Only 10 posts available, using all\n",
      "Loading 34 posts from amitheasshole dataset (16.7%)\n",
      "Found 2000 valid posts in amitheasshole\n",
      "Loading 34 posts from pop dataset (16.7%)\n",
      "Found 47 valid posts in pop\n",
      "Loading 34 posts from boomerhumor dataset (16.7%)\n",
      "Found 23 valid posts in boomerhumor\n",
      "Warning: Only 23 posts available, using all\n",
      "Loaded dataset {'pregnant': 1, 'parenting': 1, 'food': 1, 'amitheasshole': 1, 'pop': 1, 'boomerhumor': 1} with 200 posts\n",
      "google/gemma-3-4b-it newmother like history cosine_to_original_mean: 0.5624433159828186\n",
      "google/gemma-3-4b-it newmother soft prompt cosine_to_original_mean: 0.4281482994556427\n",
      "google/gemma-3-4b-it newmother summary cosine_to_original_mean: 0.5283882021903992\n",
      "google/gemma-3-4b-it newmother self defined cosine_to_original_mean: 0.6139364242553711\n",
      "Loading 200 posts from personal dataset (100.0%)\n",
      "Found 251 valid posts in personal\n",
      "Loaded dataset {'personal': 1} with 200 posts\n",
      "google/gemma-3-4b-it personal summary cosine_to_original_mean: 0.6964499354362488\n",
      "google/gemma-3-4b-it personal soft prompt cosine_to_original_mean: 0.7859781384468079\n",
      "google/gemma-3-4b-it personal like history cosine_to_original_mean: 0.823461651802063\n",
      "google/gemma-3-4b-it personal self defined cosine_to_original_mean: 0.7723168730735779\n",
      "Loading 67 posts from pop dataset (33.3%)\n",
      "Found 47 valid posts in pop\n",
      "Warning: Only 47 posts available, using all\n",
      "Loading 67 posts from religion dataset (33.3%)\n",
      "Found 28 valid posts in religion\n",
      "Warning: Only 28 posts available, using all\n",
      "Loading 67 posts from tech dataset (33.3%)\n",
      "Found 150 valid posts in tech\n",
      "Loaded dataset {'pop': 1, 'religion': 1, 'tech': 1} with 200 posts\n",
      "google/gemma-3-4b-it unalike like history cosine_to_original_mean: 0.5100383758544922\n",
      "google/gemma-3-4b-it unalike soft prompt cosine_to_original_mean: 0.5338467955589294\n",
      "google/gemma-3-4b-it unalike self defined cosine_to_original_mean: 0.34463346004486084\n",
      "google/gemma-3-4b-it unalike summary cosine_to_original_mean: 0.4716310501098633\n",
      "google/gemma-3-27b-it alike summary cosine_to_original_mean: 0.5928465127944946\n",
      "google/gemma-3-27b-it alike like history cosine_to_original_mean: 0.6795783042907715\n",
      "google/gemma-3-27b-it alike self defined cosine_to_original_mean: 0.7442626357078552\n",
      "google/gemma-3-27b-it alike soft prompt cosine_to_original_mean: 0.7634007930755615\n",
      "google/gemma-3-27b-it college summary cosine_to_original_mean: 0.37717416882514954\n",
      "google/gemma-3-27b-it college self defined cosine_to_original_mean: 0.41897669434547424\n",
      "google/gemma-3-27b-it college like history cosine_to_original_mean: 0.48098212480545044\n",
      "google/gemma-3-27b-it college soft prompt cosine_to_original_mean: 0.708412766456604\n",
      "google/gemma-3-27b-it formatspecific like history cosine_to_original_mean: 0.717499852180481\n",
      "google/gemma-3-27b-it formatspecific soft prompt cosine_to_original_mean: 0.6932076215744019\n",
      "google/gemma-3-27b-it formatspecific summary cosine_to_original_mean: 0.622982919216156\n",
      "google/gemma-3-27b-it formatspecific self defined cosine_to_original_mean: 0.49616771936416626\n",
      "google/gemma-3-27b-it nerdy self defined cosine_to_original_mean: 0.6069988012313843\n",
      "google/gemma-3-27b-it nerdy like history cosine_to_original_mean: 0.5119100213050842\n",
      "google/gemma-3-27b-it nerdy summary cosine_to_original_mean: 0.6290873885154724\n",
      "google/gemma-3-27b-it nerdy soft prompt cosine_to_original_mean: 0.8469542264938354\n",
      "google/gemma-3-27b-it newmother summary cosine_to_original_mean: 0.6767140626907349\n",
      "google/gemma-3-27b-it newmother soft prompt cosine_to_original_mean: 0.47820135951042175\n",
      "google/gemma-3-27b-it newmother self defined cosine_to_original_mean: 0.5377482771873474\n",
      "google/gemma-3-27b-it newmother like history cosine_to_original_mean: 0.7154255509376526\n",
      "google/gemma-3-27b-it personal like history cosine_to_original_mean: 0.6404145956039429\n",
      "google/gemma-3-27b-it personal summary cosine_to_original_mean: 0.5818942189216614\n",
      "google/gemma-3-27b-it personal soft prompt cosine_to_original_mean: 0.9011499285697937\n",
      "google/gemma-3-27b-it personal self defined cosine_to_original_mean: 0.6455800533294678\n",
      "google/gemma-3-27b-it unalike self defined cosine_to_original_mean: 0.6878620982170105\n",
      "google/gemma-3-27b-it unalike summary cosine_to_original_mean: 0.500739574432373\n",
      "google/gemma-3-27b-it unalike soft prompt cosine_to_original_mean: 0.6748952865600586\n",
      "google/gemma-3-27b-it unalike like history cosine_to_original_mean: 0.6236785650253296\n",
      "openai/gpt-5 alike summary cosine_to_original_mean: 0.633812665939331\n",
      "openai/gpt-5 alike like history cosine_to_original_mean: 0.6920520663261414\n",
      "openai/gpt-5 alike self defined cosine_to_original_mean: 0.6534630060195923\n",
      "openai/gpt-5 college summary cosine_to_original_mean: 0.37212073802948\n",
      "openai/gpt-5 college self defined cosine_to_original_mean: 0.5606315732002258\n",
      "openai/gpt-5 college like history cosine_to_original_mean: 0.3078196048736572\n",
      "openai/gpt-5 formatspecific like history cosine_to_original_mean: 0.6826863884925842\n",
      "openai/gpt-5 formatspecific summary cosine_to_original_mean: 0.17014189064502716\n",
      "openai/gpt-5 formatspecific self defined cosine_to_original_mean: 0.6599942445755005\n",
      "openai/gpt-5 nerdy self defined cosine_to_original_mean: 0.6030436158180237\n",
      "openai/gpt-5 nerdy like history cosine_to_original_mean: 0.3470645844936371\n",
      "openai/gpt-5 nerdy summary cosine_to_original_mean: 0.6068224906921387\n",
      "openai/gpt-5 newmother summary cosine_to_original_mean: 0.7167794704437256\n",
      "openai/gpt-5 newmother self defined cosine_to_original_mean: 0.30352985858917236\n",
      "openai/gpt-5 newmother like history cosine_to_original_mean: 0.7273622751235962\n",
      "openai/gpt-5 personal like history cosine_to_original_mean: 0.7496846318244934\n",
      "openai/gpt-5 personal summary cosine_to_original_mean: 0.6624667048454285\n",
      "openai/gpt-5 personal self defined cosine_to_original_mean: 0.6979551911354065\n",
      "openai/gpt-5 unalike self defined cosine_to_original_mean: 0.6172876358032227\n",
      "openai/gpt-5 unalike summary cosine_to_original_mean: 0.6584047675132751\n",
      "openai/gpt-5 unalike like history cosine_to_original_mean: 0.619998574256897\n",
      "Updated cosine_to_original_mean for 77 rows -> ../data/judgements/experiment_ablation_judgements_clean.json\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between original dataset means and experiment means, update JSON\n",
    "from pathlib import Path\n",
    "import torch, random, json\n",
    "\n",
    "# Deterministic sampling for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Map judgement dataset label -> composition of source datasets for the \"original\" corpus\n",
    "ORIGINAL_DATASET_COMPOSITIONS: dict[str, dict[str, int]] = {\n",
    "    'nerdy': {'nerdy': 1},\n",
    "    'personal': {'personal': 1},\n",
    "    'unalike': {'pop': 1, 'religion': 1, 'tech': 1},\n",
    "    'alike': {'tech': 1, 'nerdy': 1, 'finance': 1},\n",
    "    'formatspecific': {'copypasta': 1, 'nostupidquestions': 1, 'amitheasshole': 1},\n",
    "    'college': {'ucla': 1, 'nerdy': 1, 'okbuddy': 1, 'copypasta': 1, 'pop': 1, 'food': 1, 'animals': 1},\n",
    "    'newmother': {'pregnant': 1, 'parenting': 1, 'food': 1, 'amitheasshole': 1, 'pop': 1, 'boomerhumor': 1},\n",
    "}\n",
    "\n",
    "# Cache to avoid recomputing original means\n",
    "_original_mean_cache: dict[str, torch.Tensor] = {}\n",
    "\n",
    "\n",
    "def get_original_mean_embedding(dataset_label: str, total_posts: int = 200) -> torch.Tensor:\n",
    "    if dataset_label in _original_mean_cache:\n",
    "        return _original_mean_cache[dataset_label]\n",
    "\n",
    "    composition = ORIGINAL_DATASET_COMPOSITIONS.get(dataset_label) or {dataset_label: 1}\n",
    "    original_posts = load_datasets_proportional_objects(composition, total_posts)\n",
    "    original_texts = extract_texts(original_posts)\n",
    "    if not original_texts:\n",
    "        raise ValueError(f\"no_texts_for_original:{dataset_label}\")\n",
    "    original_embs = embed_texts(original_texts)\n",
    "    original_mean = original_embs.mean(dim=0)\n",
    "    _original_mean_cache[dataset_label] = original_mean\n",
    "    return original_mean\n",
    "\n",
    "\n",
    "# Iterate rows, compute experiment mean and cosine to original mean, persist in DF and JSON\n",
    "updated = 0\n",
    "for idx, row in df.iterrows():\n",
    "    model = str(row['model'])\n",
    "    dataset = str(row['dataset'])\n",
    "    experiment = str(row['experiment'])\n",
    "\n",
    "    posts_path = Path('..') / 'data' / 'generated' / 'experiment_ablation' / model / dataset / f\"{experiment}.json\"\n",
    "\n",
    "    cosine_val = None\n",
    "    try:\n",
    "        # Compute original mean for this dataset (cached)\n",
    "        original_mean = get_original_mean_embedding(dataset)\n",
    "\n",
    "        # Compute experiment mean\n",
    "        posts = load_posts(posts_path)\n",
    "        texts = extract_texts(posts)\n",
    "        if not texts:\n",
    "            raise ValueError('no_texts_for_experiment')\n",
    "        embs = embed_texts(texts)\n",
    "        exp_mean = embs.mean(dim=0)\n",
    "\n",
    "        # Cosine similarity between 1D means\n",
    "        cosine_val = float(torch.nn.functional.cosine_similarity(original_mean, exp_mean, dim=0).item())\n",
    "        df.loc[idx, 'cosine_to_original_mean'] = cosine_val\n",
    "        updated += 1\n",
    "    except Exception as e:\n",
    "        # Leave as missing if failure; annotate optional column for debugging\n",
    "        df.loc[idx, 'cosine_to_original_mean'] = None\n",
    "        df.loc[idx, 'cosine_error'] = str(e)\n",
    "        print(f\"{model} {dataset} {experiment} error: {e}\")\n",
    "    else:\n",
    "        print(f\"{model} {dataset} {experiment} cosine_to_original_mean: {cosine_val}\")\n",
    "\n",
    "# Persist\n",
    "out_json = Path('..') / 'data' / 'judgements' / 'experiment_ablation_judgements_clean.json'\n",
    "df.to_json(out_json, orient='records', indent=4)\n",
    "print(f\"Updated cosine_to_original_mean for {updated} rows -> {out_json}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f734efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
